{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser for Apache access log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apachelogs import LogParser\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os, glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing each line and adding it to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to parse each line and create a Pandas DataFrame to work with the data.\n",
    "I will flush the rows array to a temp csv every 1M rows to free up memory, and then I will combine these csv in a big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151a2375b33d4623932912ad34b78cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the parser params\n",
    "parser = LogParser(\"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\")\n",
    "\n",
    "cols = [\"ip\", \"date\", \"method\", \"code\", \"size\", \"useragent\", \"url\", \"http_v\"]\n",
    "rows = []\n",
    "counter = 1 #for csv name\n",
    "with open(\"access2.log\", \"r\") as fp:\n",
    "    total = sum(1 for line in fp) #calculate numb of rows for the progressbar\n",
    "    fp.seek(0) #bring the pointer back to the first line\n",
    "    for row in tqdm(parser.parse_lines(fp), total=total):\n",
    "        df_row = {}\n",
    "        df_row[\"ip\"] = row.remote_host\n",
    "        df_row[\"date\"] = row.request_time\n",
    "        df_row[\"code\"] = row.final_status\n",
    "        df_row[\"size\"] = row.bytes_sent\n",
    "        \n",
    "        req = row.request_line.split(\" \")\n",
    "        if (len(req)==3):\n",
    "            df_row[\"method\"] = req[0]\n",
    "            df_row[\"url\"] = req[1]\n",
    "            df_row[\"http_v\"] = req[2]\n",
    "        else:\n",
    "            df_row[\"method\"] = None\n",
    "            df_row[\"url\"] = None\n",
    "            df_row[\"http_v\"] = None\n",
    "        if \"User-Agent\" in row.headers_in:\n",
    "            df_row[\"useragent\"] = row.headers_in[\"User-Agent\"]\n",
    "        else:\n",
    "            df_row[\"useragent\"] = None\n",
    "        rows.append(df_row)\n",
    "        \n",
    "        #if multiple of 1M flush to csv and free up memory\n",
    "        if (len(rows)%1000000 == 0):\n",
    "            df = pd.DataFrame(rows, columns=cols)\n",
    "            df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "            counter = counter+1\n",
    "            rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flushing to csv last items left from last flush\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "counter = counter+1\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv file to create a single one\n",
    "files = glob.glob(\"access_*.csv\")\n",
    "df = pd.concat((pd.read_csv(f, sep=\"\\t\") for f in files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all csv in a single file\n",
    "df.to_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"df\" not in locals():\n",
    "    df = pd.read_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Country and City to the dataset for each IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e1ee156be44bc1ae859938443a51bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The address 127.0.0.1 is not in the database.\n",
      "The address 104.207.73.126 is not in the database.\n",
      "The address 104.207.73.83 is not in the database.\n"
     ]
    }
   ],
   "source": [
    "import geoip2.database\n",
    "\n",
    "unique_ips = df[\"ip\"].unique() #getting unique ips\n",
    "\n",
    "def getCityName(names):\n",
    "    if len(names)==0:\n",
    "        return \"\"\n",
    "    elif \"en\" in names:\n",
    "        return names[\"en\"]\n",
    "    else:\n",
    "        return names[names.keys()[0]]\n",
    "\n",
    "rows = []\n",
    "with geoip2.database.Reader('geoip/GeoLite2-City.mmdb') as reader:\n",
    "    for ip in tqdm(unique_ips, total=len(unique_ips)):\n",
    "        try:\n",
    "            info = reader.city(ip)\n",
    "            rows.append({\"lat\":info.location.latitude, \"lon\": info.location.longitude, \"city\": getCityName(info.city.names), \"country\":info.country.iso_code})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "#creating new df for ips\n",
    "ips = pd.DataFrame(rows, columns=[\"lat\", \"lon\", \"city\", \"country\"])\n",
    "del rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing country statistics and cities in file\n",
    "with open(\"output/world.json\", \"w+\") as fp:\n",
    "    countries = ips[\"country\"].value_counts().to_dict()\n",
    "    cities = ips[[\"lat\", \"lon\", \"city\"]].drop_duplicates().dropna().values.tolist()\n",
    "    json.dump({\"countries\": countries, \"cities\": cities},fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'] = df['url'].str.split('?').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-dd61377c1fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"city\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
