{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser for Apache access log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm>=4.32.2 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 1)) (4.61.2)\n",
      "Requirement already satisfied: apachelogs in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: geoip2 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: pandas in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: user-agents in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: crawlerdetect in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from -r requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: pydicti~=1.1 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from apachelogs->-r requirements.txt (line 2)) (1.1.6)\n",
      "Requirement already satisfied: attrs>=17.1 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from apachelogs->-r requirements.txt (line 2)) (21.4.0)\n",
      "Requirement already satisfied: maxminddb<3.0.0,>=2.2.0 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from geoip2->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.6.2 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from geoip2->-r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /Library/Python/3.8/site-packages (from geoip2->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.25.2 in /Library/Python/3.8/site-packages (from geoip2->-r requirements.txt (line 3)) (1.26.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from pandas->-r requirements.txt (line 4)) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from pandas->-r requirements.txt (line 4)) (2022.1)\n",
      "Requirement already satisfied: ua-parser>=0.10.0 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from user-agents->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (2.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from aiohttp<4.0.0,>=3.6.2->geoip2->-r requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Python/3.8/site-packages (from requests<3.0.0,>=2.24.0->geoip2->-r requirements.txt (line 3)) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/francescofattori/Library/Python/3.8/lib/python/site-packages (from requests<3.0.0,>=2.24.0->geoip2->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Python/3.8/site-packages (from requests<3.0.0,>=2.24.0->geoip2->-r requirements.txt (line 3)) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apachelogs import LogParser\n",
    "from user_agents import parse\n",
    "from crawlerdetect import CrawlerDetect\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os, glob\n",
    "import json\n",
    "\n",
    "crawler_detect = CrawlerDetect()\n",
    "linux_distros = [\"Ubuntu\", \"Debian\", \"Solaris\", \"Gentoo\", \"OpenBSD\", \"SUSE\", \"FreeBSD\", \"Fedora\", \"Red Hat\", \"Slackware\", \"Linux Mint\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing each line and adding it to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to parse each line and create a Pandas DataFrame to work with the data.\n",
    "I will flush the rows array to a temp csv every 1M rows to free up memory, and then I will combine these csv in a big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff87cdc538c458ea3d48a4e15ab0a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the parser params\n",
    "parser = LogParser(\"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\")\n",
    "\n",
    "cols = [\"ip\", \"date\", \"time\", \"weekday\", \"method\", \"code\", \"size\", \"url\", \"http_v\", \"bot\", \"browser\", \"os\", \"device\", \"useragent\"]\n",
    "rows = []\n",
    "counter = 1 #for csv name\n",
    "with open(\"access.log\", \"r\") as fp:\n",
    "    total = sum(1 for line in fp) #calculate numb of rows for the progressbar\n",
    "    fp.seek(0) #bring the pointer back to the first line\n",
    "    for row in tqdm(parser.parse_lines(fp), total=total):\n",
    "        df_row = {}\n",
    "        df_row[\"ip\"] = row.remote_host\n",
    "        datetime = row.request_time\n",
    "        df_row[\"date\"] = datetime.strftime(\"%d/%m/%Y\")\n",
    "        df_row[\"time\"] = datetime.strftime(\"%H:%M:%S\")\n",
    "        df_row[\"weekday\"] = datetime.weekday()\n",
    "        df_row[\"code\"] = row.final_status\n",
    "        df_row[\"size\"] = row.bytes_sent\n",
    "        \n",
    "        req = row.request_line.split(\" \")\n",
    "        if (len(req)==3):\n",
    "            df_row[\"method\"] = req[0]\n",
    "            df_row[\"url\"] = req[1].split('?')[0]\n",
    "            df_row[\"http_v\"] = req[2]\n",
    "        else:\n",
    "            df_row[\"method\"] = None\n",
    "            df_row[\"url\"] = None\n",
    "            df_row[\"http_v\"] = None\n",
    "        if \"User-Agent\" in row.headers_in and row.headers_in[\"User-Agent\"] is not None:\n",
    "            df_row[\"bot\"] = crawler_detect.isCrawler(row.headers_in[\"User-Agent\"])\n",
    "            df_row[\"device\"] = \"Bot\" #if not true, it will be changed in the next IF\n",
    "            \n",
    "            if df_row[\"bot\"] is False:\n",
    "                ua = parse(row.headers_in[\"User-Agent\"]) \n",
    "                df_row[\"browser\"] = ua.browser.family\n",
    "                \n",
    "                reqos = ua.os.family\n",
    "                if reqos in linux_distros:\n",
    "                    df_row[\"os\"] = \"Linux\"\n",
    "                elif reqos in [\"Mac OS\", \"Mac OS X\", \"macOS\"]:\n",
    "                    df_row[\"os\"] = \"macOS\"\n",
    "                else:\n",
    "                    df_row[\"os\"] = reqos\n",
    "                \n",
    "                if ua.is_pc or df_row[\"os\"] == \"Windows\" or df_row[\"os\"] == \"macOS\":\n",
    "                    df_row[\"device\"] = \"Desktop\"\n",
    "                elif ua.is_mobile:\n",
    "                    df_row[\"device\"] = \"Smartphone\"\n",
    "                elif ua.is_tablet:\n",
    "                    df_row[\"device\"] = \"Tablet\"\n",
    "                else:\n",
    "                    df_row[\"device\"] = \"Unknown\"\n",
    "                    \n",
    "            df_row[\"useragent\"] = row.headers_in[\"User-Agent\"]\n",
    "            \n",
    "        else:\n",
    "            df_row[\"useragent\"] = None\n",
    "        rows.append(df_row)\n",
    "        \n",
    "        #if multiple of 1M flush to csv and free up memory\n",
    "        if (len(rows)%1000000 == 0):\n",
    "            df = pd.DataFrame(rows, columns=cols)\n",
    "            df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "            counter = counter+1\n",
    "            rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-9cd643668b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#flushing to csv last items left from last flush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"access_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "#flushing to csv last items left from last flush\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "counter = counter+1\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv file to create a single one\n",
    "files = glob.glob(\"access_*.csv\")\n",
    "df = pd.concat((pd.read_csv(f, sep=\"\\t\") for f in files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all csv in a single file\n",
    "df.to_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"df\" not in locals():\n",
    "    df = pd.read_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Country and City to the dataset for each IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9d8017630c4819bd3d9e510c2bf03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The address 127.0.0.1 is not in the database.\n",
      "The address 104.207.73.126 is not in the database.\n",
      "The address 104.207.73.83 is not in the database.\n"
     ]
    }
   ],
   "source": [
    "import geoip2.database\n",
    "\n",
    "unique_ips = df[\"ip\"].unique() #getting unique ips\n",
    "\n",
    "def getCityName(names):\n",
    "    if len(names)==0:\n",
    "        return \"\"\n",
    "    elif \"en\" in names:\n",
    "        return names[\"en\"]\n",
    "    else:\n",
    "        return names[names.keys()[0]]\n",
    "\n",
    "rows = []\n",
    "with geoip2.database.Reader('GeoLite2-City.mmdb') as reader:\n",
    "    for ip in tqdm(unique_ips, total=len(unique_ips)):\n",
    "        try:\n",
    "            info = reader.city(ip)\n",
    "            rows.append({\"lat\":info.location.latitude, \"lon\": info.location.longitude, \"city\": getCityName(info.city.names), \"country\":info.country.iso_code})\n",
    "            df.loc[df[\"ip\"] == ip, \"country\"] = info.country.iso_code\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "#creating new df for ips\n",
    "ips = pd.DataFrame(rows, columns=[\"lat\", \"lon\", \"city\", \"country\"])\n",
    "del rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing country statistics and cities in file\n",
    "with open(\"world.json\", \"w+\") as fp:\n",
    "    countries = df[\"country\"].value_counts().to_dict()\n",
    "    cities = ips.drop_duplicates().dropna().values.tolist()\n",
    "    for city in cities:\n",
    "        if type(countries[city[3]]) is int:\n",
    "            countries[city[3]] = { \"reqs\": countries[city[3]], \"cities\": []}\n",
    "        countries[city[3]][\"cities\"].append(city[:-1])\n",
    "    json.dump({\"countries\": countries},fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b8370f01c845bb84e4353584a4e784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution by hour and weekday\n",
    "def get_dist(country):\n",
    "    current_df = df if country == \"global\" else df[df[\"country\"] == country]\n",
    "    dist = {}\n",
    "    for wd in range(7):\n",
    "        dist[wd] = []\n",
    "        for hh in range(24):\n",
    "            dist[wd].append(current_df[(current_df[\"weekday\"] == wd) & (current_df[\"time\"].str[0:2] == str(hh).zfill(2))][\"time\"].shape[0])\n",
    "    return dist\n",
    "\n",
    "with open(\"output/dist.json\", \"w+\") as fp:\n",
    "    all_dist = {}\n",
    "    countries = [\"global\"] + list(df[\"country\"].unique())\n",
    "    for country in tqdm(countries):\n",
    "        all_dist[country] = get_dist(country)\n",
    "    \n",
    "    json.dump(all_dist,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44123020b18a4a0da15982f6af3889ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#devices, os and browser\n",
    "def get_devices(country):\n",
    "    current_df = df if country == \"global\" else df[df[\"country\"] == country]\n",
    "    mydevices = current_df[current_df[\"device\"].notnull()]\n",
    "    devices = []\n",
    "    for device in mydevices[\"device\"].unique():\n",
    "        thisdevice = mydevices[mydevices[\"device\"] == device]\n",
    "        oss = []\n",
    "        browsers = [] \n",
    "        for os in thisdevice[thisdevice[\"os\"].notnull()][\"os\"].unique():\n",
    "            oss.append({\n",
    "                \"os\": os,\n",
    "                \"value\": thisdevice[thisdevice[\"os\"] == os].shape[0]\n",
    "            })\n",
    "        for browser in thisdevice[thisdevice[\"browser\"].notnull()][\"browser\"].unique():\n",
    "            browsers.append({\n",
    "                \"browser\": browser,\n",
    "                \"value\": thisdevice[thisdevice[\"browser\"] == browser].shape[0]\n",
    "            })\n",
    "        devices.append({\n",
    "            \"device\": device,\n",
    "            \"value\": thisdevice.shape[0],\n",
    "            \"os\": oss,\n",
    "            \"browser\": browsers\n",
    "        })\n",
    "    return devices\n",
    "\n",
    "with open(\"output/devices.json\", \"w+\") as fp:\n",
    "    all_devices = {}\n",
    "    for country in tqdm(countries):\n",
    "        all_devices[country] = get_devices(country)\n",
    "    json.dump(all_devices, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb88e473ee7457aad0be846d652e648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#http status on requests\n",
    "def get_status(country):\n",
    "    current_df = df if country == \"global\" else df[df[\"country\"] == country]\n",
    "    return current_df[\"code\"].value_counts().to_dict()\n",
    "\n",
    "with open(\"output/status.json\", \"w+\") as fp:\n",
    "    all_status = {}\n",
    "    for country in tqdm(countries):\n",
    "        all_status[country] = get_status(country)\n",
    "    \n",
    "    json.dump(all_status,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first time of each user\n",
    "df2 = df.copy()\n",
    "df2['date'] = pd.to_datetime(df2['date'], format=\"%d/%m/%Y\")\n",
    "\n",
    "jgroup = df2.groupby([\"ip\"], as_index=False)\n",
    "jgroup = jgroup.agg({\n",
    "    \"date\": \"min\"\n",
    "})\n",
    "del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#daily global infos\n",
    "group = df.groupby([\"date\"], as_index=False)\n",
    "group = group.agg({\n",
    "    \"ip\": \"nunique\",\n",
    "    \"url\": pd.Series.mode,\n",
    "    \"bot\": \"sum\",\n",
    "    \"size\": \"count\"\n",
    "})\n",
    "group = group.rename(columns={\"size\": \"requests\"})\n",
    "\n",
    "group_by_country = df.groupby([\"date\", \"country\"], as_index=False)\n",
    "group_by_country = group_by_country.agg({\n",
    "    \"ip\": \"nunique\",\n",
    "    \"url\": pd.Series.mode,\n",
    "    \"bot\": \"sum\",\n",
    "    \"size\": \"count\"\n",
    "})\n",
    "group_by_country = group_by_country.rename(columns={\"size\": \"requests\"})\n",
    "\n",
    "with open(\"output/requests.json\", \"w+\") as fp:\n",
    "    days = {\"global\":{}}\n",
    "    for i, row in group.iterrows():\n",
    "        days[\"global\"][row[\"date\"]] = {\n",
    "            \"reqs\": row[\"requests\"],\n",
    "            \"url\": row[\"url\"][0],\n",
    "            \"bot\": row[\"bot\"],\n",
    "            \"users\": row[\"ip\"],\n",
    "            \"newusers\": jgroup[jgroup[\"date\"] == pd.to_datetime(row[\"date\"], format=\"%d/%m/%Y\")].shape[0]\n",
    "        }\n",
    "    for i, row in group_by_country.iterrows():\n",
    "        if (row[\"country\"] not in days):\n",
    "            days[row[\"country\"]] = {}\n",
    "        days[row[\"country\"]][row[\"date\"]] = {\n",
    "            \"reqs\": row[\"requests\"],\n",
    "            \"url\": row[\"url\"][0],\n",
    "            \"bot\": row[\"bot\"]\n",
    "        }\n",
    "    json.dump(days, fp)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-04-12    428\n",
       "2016-03-22    317\n",
       "2016-03-24    284\n",
       "2016-04-05    263\n",
       "2016-03-23    260\n",
       "2016-03-25    260\n",
       "2016-04-04    227\n",
       "2016-04-11    214\n",
       "2016-03-21    202\n",
       "2016-04-13    193\n",
       "2016-03-28    180\n",
       "2016-04-08    172\n",
       "2016-03-31    172\n",
       "2016-03-29    168\n",
       "2016-04-02    162\n",
       "2016-03-27    157\n",
       "2016-04-01    152\n",
       "2016-04-19    148\n",
       "2016-04-03    140\n",
       "2016-03-30    135\n",
       "2016-04-07    133\n",
       "2016-04-15    121\n",
       "2016-04-06    120\n",
       "2016-03-26    117\n",
       "2016-04-10    106\n",
       "2016-04-20    100\n",
       "2016-04-21     99\n",
       "2016-04-14     94\n",
       "2016-04-09     92\n",
       "2016-04-26     26\n",
       "2016-04-16     22\n",
       "2016-03-16      1\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jgroup[\"date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
