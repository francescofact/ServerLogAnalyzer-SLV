{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser for Apache access log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apachelogs import LogParser\n",
    "from user_agents import parse\n",
    "from crawlerdetect import CrawlerDetect\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os, glob\n",
    "import json\n",
    "\n",
    "crawler_detect = CrawlerDetect()\n",
    "linux_distros = [\"Ubuntu\", \"Debian\", \"Solaris\", \"Gentoo\", \"OpenBSD\", \"SUSE\", \"FreeBSD\", \"Fedora\", \"Red Hat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing each line and adding it to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to parse each line and create a Pandas DataFrame to work with the data.\n",
    "I will flush the rows array to a temp csv every 1M rows to free up memory, and then I will combine these csv in a big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629517c9f9884b44b311bd2e0ab2f50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#defining the parser params\n",
    "parser = LogParser(\"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\")\n",
    "\n",
    "cols = [\"ip\", \"date\", \"time\", \"weekday\", \"method\", \"code\", \"size\", \"url\", \"http_v\", \"bot\", \"browser\", \"os\", \"device\", \"useragent\"]\n",
    "rows = []\n",
    "counter = 1 #for csv name\n",
    "with open(\"access.log\", \"r\") as fp:\n",
    "    total = sum(1 for line in fp) #calculate numb of rows for the progressbar\n",
    "    fp.seek(0) #bring the pointer back to the first line\n",
    "    for row in tqdm(parser.parse_lines(fp), total=total):\n",
    "        df_row = {}\n",
    "        df_row[\"ip\"] = row.remote_host\n",
    "        datetime = row.request_time\n",
    "        df_row[\"date\"] = datetime.strftime(\"%d/%m/%Y\")\n",
    "        df_row[\"time\"] = datetime.strftime(\"%H:%M:%S\")\n",
    "        df_row[\"weekday\"] = datetime.weekday()\n",
    "        df_row[\"code\"] = row.final_status\n",
    "        df_row[\"size\"] = row.bytes_sent\n",
    "        \n",
    "        req = row.request_line.split(\" \")\n",
    "        if (len(req)==3):\n",
    "            df_row[\"method\"] = req[0]\n",
    "            df_row[\"url\"] = req[1].split('?')[0]\n",
    "            df_row[\"http_v\"] = req[2]\n",
    "        else:\n",
    "            df_row[\"method\"] = None\n",
    "            df_row[\"url\"] = None\n",
    "            df_row[\"http_v\"] = None\n",
    "        if \"User-Agent\" in row.headers_in and row.headers_in[\"User-Agent\"] is not None:\n",
    "            df_row[\"bot\"] = crawler_detect.isCrawler(row.headers_in[\"User-Agent\"])\n",
    "                \n",
    "            if df_row[\"bot\"] is False:\n",
    "                ua = parse(row.headers_in[\"User-Agent\"]) \n",
    "                df_row[\"browser\"] = ua.browser.family\n",
    "                \n",
    "                reqos = ua.os.family\n",
    "                if reqos in linux_distros:\n",
    "                    df_row[\"os\"] = \"Linux\"\n",
    "                if reqos in [\"Mac OS\", \"Mac OS X\", \"macOS\"]:\n",
    "                    df_row[\"os\"] = \"macOS\"\n",
    "                else:\n",
    "                    df_row[\"os\"] = reqos\n",
    "                \n",
    "                if ua.is_pc or df_row[\"os\"] == \"Windows\":\n",
    "                    df_row[\"device\"] = \"Desktop\"\n",
    "                elif ua.is_mobile:\n",
    "                    df_row[\"device\"] = \"Smartphone\"\n",
    "                elif ua.is_tablet:\n",
    "                    df_row[\"device\"] = \"Tablet\"\n",
    "                else:\n",
    "                    df_row[\"device\"] = \"Unknown\"\n",
    "                    \n",
    "            df_row[\"useragent\"] = row.headers_in[\"User-Agent\"]\n",
    "            \n",
    "        else:\n",
    "            df_row[\"useragent\"] = None\n",
    "        rows.append(df_row)\n",
    "        \n",
    "        #if multiple of 1M flush to csv and free up memory\n",
    "        if (len(rows)%1000000 == 0):\n",
    "            df = pd.DataFrame(rows, columns=cols)\n",
    "            df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "            counter = counter+1\n",
    "            rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flushing to csv last items left from last flush\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "df.to_csv(\"access_\"+str(counter)+\".csv\", sep=\"\\t\")\n",
    "counter = counter+1\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all csv file to create a single one\n",
    "files = glob.glob(\"access_*.csv\")\n",
    "df = pd.concat((pd.read_csv(f, sep=\"\\t\") for f in files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all csv in a single file\n",
    "df.to_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"df\" not in locals():\n",
    "    df = pd.read_csv(\"access.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Country and City to the dataset for each IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afc66bb9b764a4684eb4ecc0ed11a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The address 127.0.0.1 is not in the database.\n",
      "The address 104.207.73.126 is not in the database.\n",
      "The address 104.207.73.83 is not in the database.\n"
     ]
    }
   ],
   "source": [
    "import geoip2.database\n",
    "\n",
    "unique_ips = df[\"ip\"].unique() #getting unique ips\n",
    "\n",
    "def getCityName(names):\n",
    "    if len(names)==0:\n",
    "        return \"\"\n",
    "    elif \"en\" in names:\n",
    "        return names[\"en\"]\n",
    "    else:\n",
    "        return names[names.keys()[0]]\n",
    "\n",
    "rows = []\n",
    "with geoip2.database.Reader('geoip/GeoLite2-City.mmdb') as reader:\n",
    "    for ip in tqdm(unique_ips, total=len(unique_ips)):\n",
    "        try:\n",
    "            info = reader.city(ip)\n",
    "            rows.append({\"lat\":info.location.latitude, \"lon\": info.location.longitude, \"city\": getCityName(info.city.names), \"country\":info.country.iso_code})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "#creating new df for ips\n",
    "ips = pd.DataFrame(rows, columns=[\"lat\", \"lon\", \"city\", \"country\"])\n",
    "del rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing country statistics and cities in file\n",
    "with open(\"output/world.json\", \"w+\") as fp:\n",
    "    countries = ips[\"country\"].value_counts().to_dict()\n",
    "    cities = ips.drop_duplicates().dropna().values.tolist()\n",
    "    for city in cities:\n",
    "        if type(countries[city[3]]) is int:\n",
    "            countries[city[3]] = { \"reqs\": countries[city[3]], \"cities\": []}\n",
    "        countries[city[3]][\"cities\"].append(city[:-1])\n",
    "    json.dump({\"countries\": countries},fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006f1909f2a445bfb579e5817b392f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution by hour and weekday\n",
    "with open(\"output/dist.json\", \"w+\") as fp:\n",
    "    dist = {}\n",
    "    for wd in tqdm(range(7)):\n",
    "        dist[wd] = []\n",
    "        for hh in range(24):\n",
    "            dist[wd].append(df[(df[\"weekday\"] == wd) & (df[\"time\"].str[0:2] == str(hh).zfill(2))][\"time\"].shape[0])\n",
    "    json.dump(dist,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1830,\n",
       "  2136,\n",
       "  2150,\n",
       "  2282,\n",
       "  1861,\n",
       "  2202,\n",
       "  2414,\n",
       "  1968,\n",
       "  2246,\n",
       "  2982,\n",
       "  3500,\n",
       "  3345,\n",
       "  2999,\n",
       "  3628,\n",
       "  7001,\n",
       "  10643,\n",
       "  11215,\n",
       "  7834,\n",
       "  12437,\n",
       "  9686,\n",
       "  8980,\n",
       "  5737,\n",
       "  3122,\n",
       "  2176],\n",
       " 1: [2285,\n",
       "  2397,\n",
       "  3220,\n",
       "  2195,\n",
       "  1986,\n",
       "  1849,\n",
       "  1871,\n",
       "  2852,\n",
       "  5834,\n",
       "  7374,\n",
       "  12617,\n",
       "  18756,\n",
       "  15111,\n",
       "  7379,\n",
       "  8620,\n",
       "  9690,\n",
       "  11964,\n",
       "  9817,\n",
       "  6849,\n",
       "  4750,\n",
       "  8755,\n",
       "  5449,\n",
       "  4240,\n",
       "  1572],\n",
       " 2: [1066,\n",
       "  1424,\n",
       "  2705,\n",
       "  629,\n",
       "  913,\n",
       "  1021,\n",
       "  1080,\n",
       "  890,\n",
       "  3315,\n",
       "  7388,\n",
       "  6800,\n",
       "  7359,\n",
       "  8004,\n",
       "  7973,\n",
       "  8562,\n",
       "  14586,\n",
       "  4183,\n",
       "  4698,\n",
       "  4448,\n",
       "  2126,\n",
       "  3096,\n",
       "  4201,\n",
       "  2591,\n",
       "  1640],\n",
       " 3: [1503,\n",
       "  1142,\n",
       "  1614,\n",
       "  898,\n",
       "  2376,\n",
       "  1244,\n",
       "  1107,\n",
       "  2140,\n",
       "  2310,\n",
       "  5338,\n",
       "  6282,\n",
       "  4288,\n",
       "  2974,\n",
       "  2918,\n",
       "  8060,\n",
       "  8040,\n",
       "  5659,\n",
       "  3129,\n",
       "  3562,\n",
       "  3372,\n",
       "  3546,\n",
       "  3163,\n",
       "  2490,\n",
       "  1596],\n",
       " 4: [650,\n",
       "  863,\n",
       "  1308,\n",
       "  1088,\n",
       "  916,\n",
       "  777,\n",
       "  827,\n",
       "  1093,\n",
       "  2045,\n",
       "  5857,\n",
       "  2167,\n",
       "  4363,\n",
       "  2877,\n",
       "  3219,\n",
       "  5316,\n",
       "  3896,\n",
       "  2614,\n",
       "  2402,\n",
       "  2625,\n",
       "  2092,\n",
       "  2640,\n",
       "  1982,\n",
       "  1724,\n",
       "  2390],\n",
       " 5: [1490,\n",
       "  600,\n",
       "  1076,\n",
       "  936,\n",
       "  736,\n",
       "  454,\n",
       "  850,\n",
       "  653,\n",
       "  2539,\n",
       "  1309,\n",
       "  1827,\n",
       "  1728,\n",
       "  2196,\n",
       "  2184,\n",
       "  1622,\n",
       "  2290,\n",
       "  1894,\n",
       "  3059,\n",
       "  1364,\n",
       "  1485,\n",
       "  2574,\n",
       "  2292,\n",
       "  1157,\n",
       "  1856],\n",
       " 6: [1428,\n",
       "  865,\n",
       "  1107,\n",
       "  900,\n",
       "  1189,\n",
       "  1479,\n",
       "  963,\n",
       "  1353,\n",
       "  2533,\n",
       "  2622,\n",
       "  1665,\n",
       "  1304,\n",
       "  2188,\n",
       "  1941,\n",
       "  2737,\n",
       "  2748,\n",
       "  2327,\n",
       "  2578,\n",
       "  2642,\n",
       "  4457,\n",
       "  2661,\n",
       "  2679,\n",
       "  2756,\n",
       "  1889]}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
